{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Spectral-Spatial Linear Transformer on Houston Dataset - Google Colab\n",
        "\n",
        "This notebook trains the **Spectral-Spatial Linear Transformer** model on the Houston hyperspectral dataset.\n",
        "\n",
        "## Model Architecture - NEW!\n",
        "- **Spectral-Spatial Linear Attention**: Factorized attention with O(N) complexity\n",
        "  - Linear spatial attention for efficient token mixing\n",
        "  - Spectral gating mechanism for band correlations\n",
        "- **Band-Weighted Pooling**: Learnable spectral band weighting (replaces simple pooling)\n",
        "- **Global Attention Block**: Single full-attention block for long-range context\n",
        "- **Ultra-low FLOPs and Latency**: Linear complexity for faster training and inference\n",
        "\n",
        "## Dataset\n",
        "- **Houston**: Hyperspectral image dataset\n",
        "- **Spectral Bands**: 144\n",
        "- **Classes**: 15 land-cover categories\n",
        "- **Window Size**: 5\u00d75 spatial patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q transformers scikit-learn seaborn einops thop scipy h5py\n",
        "\n",
        "print(\"\u2713 Packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import scipy.io\n",
        "import h5py\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score, precision_score, recall_score, f1_score\n",
        "import time\n",
        "from einops import rearrange\n",
        "from thop import profile\n",
        "import os\n",
        "\n",
        "print(\"\u2713 Libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# NEW: Spectral-Spatial Linear Transformer Architecture\n",
        "# ============================================================\n",
        "\n",
        "# 1. Band-weighted pooling (NEW - replaces simple spectral attention)\n",
        "class BandWeightedPooling(nn.Module):\n",
        "    \"\"\"\n",
        "    Learnable spectral-band weighting for global token aggregation.\n",
        "    Provides explicit spectral inductive bias.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, N, C)\n",
        "        w = torch.softmax(self.weights, dim=0)\n",
        "        return (x * w).sum(dim=1)\n",
        "\n",
        "\n",
        "# 2. Spectral-Spatial Factorized Linear Attention (CORE NOVELTY)\n",
        "class SpectralSpatialLinearAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Linear attention with explicit spectral gating.\n",
        "    Spatial mixing via linear attention, spectral mixing via channel gate.\n",
        "    O(N) complexity instead of O(N\u00b2)!\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, num_heads=8):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        \n",
        "        # Spectral gate (explicit inductive bias)\n",
        "        self.spectral_gate = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim // 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim // 4, dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim)\n",
        "        q, k, v = qkv.unbind(dim=2)\n",
        "        \n",
        "        # Linear spatial attention\n",
        "        k = k.softmax(dim=1)\n",
        "        context = torch.einsum('bnhd,bnhv->bhdv', k, v)\n",
        "        out = torch.einsum('bnhd,bhdv->bnhv', q, context)\n",
        "        out = out.reshape(B, N, C)\n",
        "        \n",
        "        # Spectral gating\n",
        "        gate = self.spectral_gate(x)\n",
        "        out = out * gate\n",
        "        \n",
        "        return self.proj(out)\n",
        "\n",
        "\n",
        "# 3. Global attention block (NEW - accuracy stabilizer)\n",
        "class GlobalAttentionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Single full-attention block to restore long-range interactions.\n",
        "    Cost is minimal, accuracy gain is large.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.attn = nn.MultiheadAttention(dim, num_heads, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.norm(x)\n",
        "        out, _ = self.attn(h, h, h)\n",
        "        return x + out\n",
        "\n",
        "\n",
        "# 4. Transformer Block (UPDATED)\n",
        "class SpectralSpatialViTBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4.):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = SpectralSpatialLinearAttention(dim, num_heads)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, int(dim * mlp_ratio)),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(int(dim * mlp_ratio), dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "# 5. FINAL MODEL (NEW ARCHITECTURE)\n",
        "class SpectralSpatialLinearTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Spectral-Spatial Linear Transformer for Hyperspectral Image Classification\n",
        "    \n",
        "    Key innovations:\n",
        "    - Linear attention (O(N) complexity) with spectral gating\n",
        "    - Band-weighted pooling for interpretable aggregation  \n",
        "    - Single global attention for accuracy boost\n",
        "    - Ultra-low FLOPs and latency\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_size=5,\n",
        "        patch_size=1,\n",
        "        num_channels=103,\n",
        "        num_classes=9,\n",
        "        embed_dim=768,\n",
        "        depth=6,\n",
        "        num_heads=12,\n",
        "        mlp_ratio=4.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\"embed_dim must be divisible by num_heads\")\n",
        "        \n",
        "        # Patch embedding\n",
        "        self.patch_embed = nn.Conv2d(\n",
        "            num_channels,\n",
        "            embed_dim,\n",
        "            kernel_size=patch_size,\n",
        "            stride=patch_size\n",
        "        )\n",
        "        num_patches_h = (image_size - patch_size) // patch_size + 1\n",
        "        num_patches_w = (image_size - patch_size) // patch_size + 1\n",
        "        num_patches = num_patches_h * num_patches_w\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
        "        \n",
        "        # Linear attention blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            SpectralSpatialViTBlock(embed_dim, num_heads, mlp_ratio)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "        \n",
        "        # Single global attention block\n",
        "        self.global_block = GlobalAttentionBlock(embed_dim, num_heads)\n",
        "        \n",
        "        # Spectral pooling + classifier\n",
        "        self.spectral_pool = BandWeightedPooling(embed_dim)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, labels=None):\n",
        "        # Patchify\n",
        "        x = self.patch_embed(x)\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        x = x + self.pos_embed\n",
        "        \n",
        "        # Linear transformer blocks\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "        \n",
        "        # Global attention refinement\n",
        "        x = self.global_block(x)\n",
        "        \n",
        "        # Spectral pooling\n",
        "        x = self.spectral_pool(x)\n",
        "        x = self.norm(x)\n",
        "        logits = self.head(x)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "            return {\"loss\": loss, \"logits\": logits}\n",
        "        return {\"logits\": logits}\n",
        "\n",
        "# Alias for compatibility\n",
        "newFastViT = SpectralSpatialLinearTransformer\n",
        "\n",
        "print(\"\u2713 NEW Model architecture defined!\")\n",
        "print(\"  - Spectral-Spatial Linear Attention (O(N) complexity)\")\n",
        "print(\"  - Band-Weighted Pooling (interpretable)\")\n",
        "print(\"  - Global Attention Block (accuracy boost)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Define Data Loader Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Loader Functions\n",
        "def load_houston(image_file, gt_file):\n",
        "    \"\"\"\n",
        "    Load Houston hyperspectral dataset from .mat files.\n",
        "    Handles both MATLAB v7.3 (HDF5) and older formats.\n",
        "    \"\"\"\n",
        "    print(\"Loading Houston dataset...\")\n",
        "    \n",
        "    def load_mat_file(file_path):\n",
        "        \"\"\"Load .mat file, handling both v7.3 (HDF5) and older formats.\"\"\"\n",
        "        # First verify file exists and is readable\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "        \n",
        "        file_size = os.path.getsize(file_path)\n",
        "        if file_size < 100:\n",
        "            raise ValueError(f\"File too small ({file_size} bytes), likely corrupted: {file_path}\")\n",
        "        \n",
        "        # Check file header to determine format\n",
        "        with open(file_path, 'rb') as f:\n",
        "            header = f.read(4)\n",
        "        \n",
        "        # Try h5py first if it looks like HDF5 (MATLAB v7.3)\n",
        "        if header == b'MATL' or header[:2] == b'\\x00\\x00':\n",
        "            try:\n",
        "                print(f\"  Detected HDF5 format, using h5py...\")\n",
        "                f = h5py.File(file_path, 'r')\n",
        "                keys = list(f.keys())\n",
        "                print(f\"  Found keys: {keys}\")\n",
        "                return f, keys, 'h5py'\n",
        "            except Exception as e:\n",
        "                print(f\"  h5py failed: {e}, trying scipy...\")\n",
        "        \n",
        "        # Try scipy for older MATLAB formats\n",
        "        try:\n",
        "            mat = scipy.io.loadmat(file_path)\n",
        "            keys = [k for k in mat.keys() if not k.startswith('__')]\n",
        "            print(f\"  Found keys: {keys}\")\n",
        "            return mat, keys, 'scipy'\n",
        "        except (ValueError, NotImplementedError) as e:\n",
        "            # If scipy fails, try h5py as fallback\n",
        "            print(f\"  scipy.io.loadmat failed ({e}), trying h5py...\")\n",
        "            try:\n",
        "                f = h5py.File(file_path, 'r')\n",
        "                keys = list(f.keys())\n",
        "                print(f\"  Found keys: {keys}\")\n",
        "                return f, keys, 'h5py'\n",
        "            except Exception as e2:\n",
        "                # Provide helpful error message\n",
        "                error_msg = f\"Could not load {file_path}:\\n\"\n",
        "                error_msg += f\"  - scipy error: {e}\\n\"\n",
        "                error_msg += f\"  - h5py error: {e2}\\n\"\n",
        "                error_msg += f\"  - File size: {file_size} bytes\\n\"\n",
        "                error_msg += f\"  - File header: {header.hex()}\\n\"\n",
        "                error_msg += \"\\nThe file might be corrupted or in an unsupported format.\\n\"\n",
        "                error_msg += \"Please verify the file was downloaded correctly.\"\n",
        "                raise ValueError(error_msg)\n",
        "    \n",
        "    # Load both files\n",
        "    image_mat, image_keys, image_format = load_mat_file(image_file)\n",
        "    gt_mat, gt_keys, gt_format = load_mat_file(gt_file)\n",
        "    \n",
        "    print(f\"  Image file format: {image_format}\")\n",
        "    print(f\"  GT file format: {gt_format}\")\n",
        "    \n",
        "    # Helper function to get data from either format\n",
        "    def get_data(mat_obj, key, format_type):\n",
        "        if format_type == 'scipy':\n",
        "            return mat_obj[key]\n",
        "        else:  # h5py\n",
        "            # HDF5 files can store data directly or as references\n",
        "            data_ref = mat_obj[key]\n",
        "            \n",
        "            # If it's a dataset, read it directly\n",
        "            if isinstance(data_ref, h5py.Dataset):\n",
        "                data = np.array(data_ref[:])\n",
        "                return data\n",
        "            \n",
        "            # If it's a reference, follow it\n",
        "            elif isinstance(data_ref, h5py.Reference):\n",
        "                ref_obj = mat_obj[data_ref]\n",
        "                if isinstance(ref_obj, h5py.Dataset):\n",
        "                    return np.array(ref_obj[:])\n",
        "                else:\n",
        "                    return np.array(ref_obj)\n",
        "            \n",
        "            # If it's already an array-like object\n",
        "            elif hasattr(data_ref, '__array__'):\n",
        "                return np.array(data_ref)\n",
        "            \n",
        "            # Try to read as dataset\n",
        "            else:\n",
        "                try:\n",
        "                    return np.array(data_ref[:])\n",
        "                except:\n",
        "                    return np.array(data_ref)\n",
        "    \n",
        "    # Load image data\n",
        "    if len(image_keys) == 0:\n",
        "        raise ValueError(\"No data keys found in image file.\")\n",
        "    elif len(image_keys) == 1:\n",
        "        image_data = get_data(image_mat, image_keys[0], image_format)\n",
        "        print(f\"Using image data key: '{image_keys[0]}'\")\n",
        "    else:\n",
        "        possible_image_keys = ['ori_data', 'houston', 'Houston', 'Houston13', 'data', 'image', 'HSI']\n",
        "        image_data = None\n",
        "        for key in possible_image_keys:\n",
        "            if key in image_keys:\n",
        "                image_data = get_data(image_mat, key, image_format)\n",
        "                print(f\"Found image data with key: '{key}'\")\n",
        "                break\n",
        "        if image_data is None:\n",
        "            image_data = get_data(image_mat, image_keys[0], image_format)\n",
        "            print(f\"Warning: Using first available key '{image_keys[0]}' from: {image_keys}\")\n",
        "    \n",
        "    # Load ground truth data\n",
        "    if len(gt_keys) == 0:\n",
        "        raise ValueError(\"No data keys found in gt file.\")\n",
        "    elif len(gt_keys) == 1:\n",
        "        ground_truth = get_data(gt_mat, gt_keys[0], gt_format)\n",
        "        print(f\"Using ground truth key: '{gt_keys[0]}'\")\n",
        "    else:\n",
        "        possible_gt_keys = ['map', 'houston_gt', 'Houston_gt', 'Houston13_7gt', 'gt', 'ground_truth', 'label']\n",
        "        ground_truth = None\n",
        "        for key in possible_gt_keys:\n",
        "            if key in gt_keys:\n",
        "                ground_truth = get_data(gt_mat, key, gt_format)\n",
        "                print(f\"Found ground truth with key: '{key}'\")\n",
        "                break\n",
        "        if ground_truth is None:\n",
        "            ground_truth = get_data(gt_mat, gt_keys[0], gt_format)\n",
        "            print(f\"Warning: Using first available key '{gt_keys[0]}' from: {gt_keys}\")\n",
        "    \n",
        "    # Ensure data is numpy array and handle transposition for HDF5\n",
        "    if isinstance(image_data, np.ndarray):\n",
        "        pass  # Already numpy array\n",
        "    else:\n",
        "        image_data = np.array(image_data)\n",
        "    \n",
        "    if isinstance(ground_truth, np.ndarray):\n",
        "        pass  # Already numpy array\n",
        "    else:\n",
        "        ground_truth = np.array(ground_truth)\n",
        "    \n",
        "    # HDF5 files often store data transposed, check and fix if needed\n",
        "    if image_format == 'h5py' and len(image_data.shape) == 3:\n",
        "        # Check if dimensions look transposed (C, H, W instead of H, W, C)\n",
        "        if image_data.shape[0] < image_data.shape[2]:\n",
        "            image_data = np.transpose(image_data, (1, 2, 0))\n",
        "            print(\"  Transposed image data from (C, H, W) to (H, W, C)\")\n",
        "    \n",
        "    if gt_format == 'h5py' and len(ground_truth.shape) == 2:\n",
        "        # Ground truth should be (H, W), check if transposed\n",
        "        pass  # Usually correct for GT\n",
        "    \n",
        "    print(f\"Image data shape: {image_data.shape}\")\n",
        "    print(f\"Ground truth shape: {ground_truth.shape}\")\n",
        "    \n",
        "    # Close HDF5 files if opened\n",
        "    if image_format == 'h5py':\n",
        "        image_mat.close()\n",
        "    if gt_format == 'h5py':\n",
        "        gt_mat.close()\n",
        "    \n",
        "    return image_data, ground_truth\n",
        "\n",
        "\n",
        "def preprocess_data(image_data, ground_truth, window_size=5):\n",
        "    \"\"\"Preprocess hyperspectral data to extract spatial-spectral patches.\"\"\"\n",
        "    image_data = (image_data - np.min(image_data)) / (np.max(image_data) - np.min(image_data))\n",
        "    padded_image = np.pad(image_data, ((window_size//2, window_size//2),\n",
        "                                       (window_size//2, window_size//2),\n",
        "                                       (0, 0)), mode='reflect')\n",
        "    spatial_spectral_data = np.zeros((image_data.shape[0], image_data.shape[1],\n",
        "                                      window_size, window_size, image_data.shape[2]))\n",
        "    for i in range(image_data.shape[0]):\n",
        "        for j in range(image_data.shape[1]):\n",
        "            spatial_spectral_data[i, j] = padded_image[i:i+window_size, j:j+window_size, :]\n",
        "\n",
        "    spatial_spectral_data = spatial_spectral_data.reshape(-1, window_size, window_size, image_data.shape[2])\n",
        "    y = ground_truth.flatten()\n",
        "    mask = y != 0\n",
        "    spatial_spectral_data = spatial_spectral_data[mask]\n",
        "    y = y[mask]\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(y)\n",
        "    return spatial_spectral_data, y, label_encoder\n",
        "\n",
        "\n",
        "class HyperspectralDataset(Dataset):\n",
        "    def __init__(self, spatial_spectral_data, labels):\n",
        "        self.spatial_spectral_data = spatial_spectral_data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.spatial_spectral_data[idx].transpose(2, 0, 1)\n",
        "        label = self.labels[idx]\n",
        "        return {\n",
        "            'x': torch.tensor(feature, dtype=torch.float32),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "print(\"\u2713 Data loader functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Define Utility Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility Functions\n",
        "def calculate_latency_per_image(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_time, total_images = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            inputs = batch['x'].to(device)\n",
        "            batch_size = inputs.shape[0]\n",
        "            total_images += batch_size\n",
        "            start_time = time.time()\n",
        "            _ = model(inputs)\n",
        "            total_time += (time.time() - start_time)\n",
        "    return (total_time / total_images) * 1000\n",
        "\n",
        "def calculate_throughput(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_samples, total_time = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            inputs = batch['x'].to(device)\n",
        "            batch_size = inputs.size(0)\n",
        "            start_time = time.time()\n",
        "            _ = model(inputs)\n",
        "            total_time += time.time() - start_time\n",
        "            total_samples += batch_size\n",
        "    return total_samples / total_time\n",
        "\n",
        "def overall_accuracy(y_true, y_pred):\n",
        "    return np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "def average_accuracy(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
        "    return np.nanmean(class_accuracies)\n",
        "\n",
        "def kappa_coefficient(y_true, y_pred):\n",
        "    return cohen_kappa_score(y_true, y_pred)\n",
        "\n",
        "def calculate_f1_precision_recall(y_true, y_pred):\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    return f1, precision, recall\n",
        "\n",
        "def count_model_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad) / 1_000_000\n",
        "\n",
        "def calculate_gflops(model, dataset, device):\n",
        "    sample = dataset[0]['x'].unsqueeze(0).to(device)\n",
        "    flops, _ = profile(model, inputs=(sample,), verbose=False)\n",
        "    return flops / 1e9\n",
        "\n",
        "print(\"\u2713 Utility functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Download Houston Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataset directory\n",
        "os.makedirs('dataset', exist_ok=True)\n",
        "\n",
        "# Download Houston dataset with verification\n",
        "print(\"Downloading Houston dataset...\")\n",
        "import urllib.request\n",
        "\n",
        "def download_file(url, dest_path, description):\n",
        "    \"\"\"Download file with retry and verification.\"\"\"\n",
        "    max_retries = 3\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"  Downloading {description}... (attempt {attempt + 1}/{max_retries})\")\n",
        "            urllib.request.urlretrieve(url, dest_path)\n",
        "            \n",
        "            # Verify file was downloaded and has content\n",
        "            if os.path.exists(dest_path):\n",
        "                size = os.path.getsize(dest_path)\n",
        "                if size > 1000:  # At least 1KB\n",
        "                    print(f\"    \u2713 Downloaded: {size / 1024:.1f} KB\")\n",
        "                    return True\n",
        "                else:\n",
        "                    print(f\"    \u2717 File too small ({size} bytes), retrying...\")\n",
        "                    os.remove(dest_path)\n",
        "            else:\n",
        "                print(f\"    \u2717 File not found, retrying...\")\n",
        "        except Exception as e:\n",
        "            print(f\"    \u2717 Error: {e}, retrying...\")\n",
        "            if os.path.exists(dest_path):\n",
        "                os.remove(dest_path)\n",
        "    \n",
        "    return False\n",
        "\n",
        "# Try multiple download sources\n",
        "download_sources = [\n",
        "    {\n",
        "        'image': \"https://github.com/YuxiangZhang-BIT/Data-CSHSI/raw/main/datasets/Houston/Houston13.mat\",\n",
        "        'gt': \"https://github.com/YuxiangZhang-BIT/Data-CSHSI/raw/main/datasets/Houston/Houston13_7gt.mat\"\n",
        "    },\n",
        "    {\n",
        "        'image': \"https://raw.githubusercontent.com/YuxiangZhang-BIT/Data-CSHSI/main/datasets/Houston/Houston13.mat\",\n",
        "        'gt': \"https://raw.githubusercontent.com/YuxiangZhang-BIT/Data-CSHSI/main/datasets/Houston/Houston13_7gt.mat\"\n",
        "    }\n",
        "]\n",
        "\n",
        "success = False\n",
        "for i, source in enumerate(download_sources):\n",
        "    print(f\"\\nTrying download source {i+1}...\")\n",
        "    if download_file(source['image'], \"dataset/Houston13.mat\", \"Houston13.mat\"):\n",
        "        if download_file(source['gt'], \"dataset/Houston13_7gt.mat\", \"Houston13_7gt.mat\"):\n",
        "            success = True\n",
        "            break\n",
        "\n",
        "if not success:\n",
        "    print(\"\\n\u26a0 Warning: Direct download failed. The files might be too large for GitHub raw links.\")\n",
        "    print(\"Please manually upload the Houston dataset files:\")\n",
        "    print(\"  1. Go to: https://github.com/YuxiangZhang-BIT/Data-CSHSI\")\n",
        "    print(\"  2. Navigate to datasets/Houston/\")\n",
        "    print(\"  3. Download Houston13.mat and Houston13_7gt.mat\")\n",
        "    print(\"  4. Upload them to Colab using: Files \u2192 Upload\")\n",
        "    print(\"  5. Move them to the dataset/ folder\")\n",
        "else:\n",
        "    print(\"\\n\u2713 Dataset downloaded successfully!\")\n",
        "    print(\"\\nFile verification:\")\n",
        "    for f in os.listdir('dataset'):\n",
        "        if f.endswith('.mat'):\n",
        "            size = os.path.getsize(f'dataset/{f}') / 1024  # KB\n",
        "            print(f\"  {f}: {size:.1f} KB\")\n",
        "            \n",
        "            # Check file header to verify format\n",
        "            with open(f'dataset/{f}', 'rb') as file:\n",
        "                header = file.read(4)\n",
        "                if header == b'MATL':\n",
        "                    print(f\"    Format: MATLAB v7.3 (HDF5)\")\n",
        "                elif header[:2] == b'MI':\n",
        "                    print(f\"    Format: MATLAB v6/v7\")\n",
        "                else:\n",
        "                    print(f\"    Format: Unknown (header: {header.hex()})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative: Manual File Upload\n",
        "\n",
        "If automatic download fails, you can manually upload the files:\n",
        "\n",
        "1. **Download files manually**:\n",
        "   - Visit: https://github.com/YuxiangZhang-BIT/Data-CSHSI/tree/main/datasets/Houston\n",
        "   - Download `Houston13.mat` and `Houston13_7gt.mat`\n",
        "   - Or use direct links if available\n",
        "\n",
        "2. **Upload to Colab**:\n",
        "   - Use the file browser on the left sidebar\n",
        "   - Click \"Upload\" and select the .mat files\n",
        "   - Or use the code below to upload via dialog\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative: Upload files manually (uncomment if download failed)\n",
        "# from google.colab import files\n",
        "# import shutil\n",
        "\n",
        "# print(\"Please upload Houston13.mat:\")\n",
        "# uploaded = files.upload()\n",
        "# for filename in uploaded.keys():\n",
        "#     shutil.move(filename, f\"dataset/{filename}\")\n",
        "#     print(f\"Moved {filename} to dataset/\")\n",
        "\n",
        "# print(\"\\nPlease upload Houston13_7gt.mat:\")\n",
        "# uploaded = files.upload()\n",
        "# for filename in uploaded.keys():\n",
        "#     shutil.move(filename, f\"dataset/{filename}\")\n",
        "#     print(f\"Moved {filename} to dataset/\")\n",
        "\n",
        "# Verify files exist\n",
        "if os.path.exists(\"dataset/Houston13.mat\") and os.path.exists(\"dataset/Houston13_7gt.mat\"):\n",
        "    print(\"\u2713 Dataset files found!\")\n",
        "    for f in ['Houston13.mat', 'Houston13_7gt.mat']:\n",
        "        size = os.path.getsize(f'dataset/{f}') / (1024*1024)  # MB\n",
        "        print(f\"  {f}: {size:.2f} MB\")\n",
        "else:\n",
        "    print(\"\u26a0 Dataset files not found. Please download or upload them.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Load and Preprocess Dataset\n",
        "\n",
        "**Note**: If you see errors about file format, the files might be corrupted. Try:\n",
        "1. Re-downloading the files manually\n",
        "2. Using the manual upload option above\n",
        "3. Checking that files are actual .mat files (not HTML error pages)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Load and Preprocess Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Houston dataset\n",
        "image_file = \"./dataset/Houston13.mat\"\n",
        "gt_file = \"./dataset/Houston13_7gt.mat\"\n",
        "\n",
        "# First, verify files exist and check their content\n",
        "print(\"Checking files...\")\n",
        "for file_path in [image_file, gt_file]:\n",
        "    if os.path.exists(file_path):\n",
        "        size = os.path.getsize(file_path)\n",
        "        print(f\"  {file_path}: {size / (1024*1024):.2f} MB\")\n",
        "        \n",
        "        # Check if file might be an HTML error page (common with failed downloads)\n",
        "        with open(file_path, 'rb') as f:\n",
        "            first_bytes = f.read(200)\n",
        "            if b'<!DOCTYPE' in first_bytes or b'<html' in first_bytes.lower() or b'404' in first_bytes:\n",
        "                print(f\"    \u26a0 WARNING: File appears to be HTML (download may have failed)\")\n",
        "                print(f\"    Please manually download and upload the file\")\n",
        "                print(f\"    Visit: https://github.com/YuxiangZhang-BIT/Data-CSHSI/tree/main/datasets/Houston\")\n",
        "    else:\n",
        "        print(f\"  {file_path}: NOT FOUND\")\n",
        "        print(f\"    Please download from: https://github.com/YuxiangZhang-BIT/Data-CSHSI/tree/main/datasets/Houston\")\n",
        "\n",
        "print(\"\\nLoading dataset...\")\n",
        "try:\n",
        "    image_data, ground_truth = load_houston(image_file, gt_file)\n",
        "    print(f\"\\n\u2713 Dataset loaded successfully!\")\n",
        "    print(f\"Image data shape: {image_data.shape}\")\n",
        "    print(f\"Ground truth shape: {ground_truth.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n\u2717 Error loading dataset: {e}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"1. Verify files are valid .mat files (not HTML error pages)\")\n",
        "    print(\"2. Try manually uploading files using the upload cell above\")\n",
        "    print(\"3. Check file sizes - they should be several MB, not KB\")\n",
        "    print(\"4. Ensure files are in the dataset/ folder\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess data with 5x5 window size\n",
        "window_size = 5\n",
        "spatial_spectral_data, y, label_encoder = preprocess_data(image_data, ground_truth, window_size=window_size)\n",
        "\n",
        "num_classes = len(np.unique(y))\n",
        "num_channels = spatial_spectral_data.shape[-1]\n",
        "\n",
        "print(f\"\\n\u2713 Data preprocessed successfully!\")\n",
        "print(f\"Spatial-spectral data shape: {spatial_spectral_data.shape}\")\n",
        "print(f\"Labels shape: {y.shape}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Number of spectral bands: {num_channels}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Split Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split dataset: 80% train, 20% test\n",
        "train_indices, test_indices = train_test_split(\n",
        "    np.arange(len(y)),\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = HyperspectralDataset(spatial_spectral_data[train_indices], y[train_indices])\n",
        "test_dataset = HyperspectralDataset(spatial_spectral_data[test_indices], y[test_indices])\n",
        "\n",
        "print(f\"\u2713 Dataset split successfully!\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Testing samples: {len(test_dataset)}\")\n",
        "print(f\"Train class distribution: {np.bincount(y[train_indices])}\")\n",
        "print(f\"Test class distribution: {np.bincount(y[test_indices])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Initialize Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model configuration for Houston dataset\n",
        "patch_size = 4\n",
        "embed_dim = 192  # Must be divisible by num_heads\n",
        "num_heads = 4\n",
        "depth = 4\n",
        "\n",
        "# Validate configuration\n",
        "if embed_dim % num_heads != 0:\n",
        "    raise ValueError(f\"embed_dim ({embed_dim}) must be divisible by num_heads ({num_heads})\")\n",
        "\n",
        "# Calculate actual number of patches\n",
        "actual_patches_h = (window_size - patch_size) // patch_size + 1\n",
        "actual_patches_w = (window_size - patch_size) // patch_size + 1\n",
        "actual_num_patches = actual_patches_h * actual_patches_w\n",
        "\n",
        "print(f\"Model Configuration:\")\n",
        "print(f\"  Image size: {window_size}x{window_size}\")\n",
        "print(f\"  Patch size: {patch_size}x{patch_size}\")\n",
        "print(f\"  Actual patches: {actual_patches_h}x{actual_patches_w} = {actual_num_patches}\")\n",
        "print(f\"  Number of spectral bands: {num_channels}\")\n",
        "print(f\"  Number of classes: {num_classes}\")\n",
        "print(f\"  Embed dim: {embed_dim} (divisible by num_heads={num_heads} \u2713)\")\n",
        "print(f\"  Head dim: {embed_dim // num_heads}\")\n",
        "print(f\"  Depth: {depth}\")\n",
        "\n",
        "model = newFastViT(\n",
        "    image_size=window_size,\n",
        "    patch_size=patch_size,\n",
        "    num_channels=num_channels,  # Houston: 144 bands\n",
        "    num_classes=num_classes,     # Houston: 15 classes\n",
        "    embed_dim=embed_dim,\n",
        "    depth=depth,\n",
        "    num_heads=num_heads,\n",
        "    mlp_ratio=4.0\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(f\"\\n\u2713 Model initialized successfully!\")\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Number of parameters: {count_model_parameters(model):.2f} M\")\n",
        "\n",
        "# Calculate GFLOPs\n",
        "try:\n",
        "    gflops = calculate_gflops(model, train_dataset, device)\n",
        "    print(f\"GFLOPs: {gflops:.2f}\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not calculate GFLOPs: {e}\")\n",
        "    gflops = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Setup Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_houston_spectral_spatial\",\n",
        "    num_train_epochs=20,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=3,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False\n",
        ")\n",
        "\n",
        "# Data collator\n",
        "def data_collator(data):\n",
        "    return {\n",
        "        'x': torch.stack([d['x'] for d in data]),\n",
        "        'labels': torch.stack([d['labels'] for d in data])\n",
        "    }\n",
        "\n",
        "# Compute metrics function\n",
        "def compute_metrics(p):\n",
        "    predictions = p.predictions.argmax(-1)\n",
        "    labels = p.label_ids\n",
        "    accuracy = (predictions == labels).mean()\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "print(\"\u2713 Trainer setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "print(\"This may take a while depending on your hardware...\")\n",
        "trainer.train()\n",
        "print(\"\u2713 Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"\\nEvaluation Results:\")\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"{key}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Generate Predictions and Calculate Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "y_true = y[test_indices]\n",
        "\n",
        "# Calculate metrics\n",
        "oa = overall_accuracy(y_true, y_pred)\n",
        "aa = average_accuracy(y_true, y_pred)\n",
        "kappa = kappa_coefficient(y_true, y_pred)\n",
        "f1, precision, recall = calculate_f1_precision_recall(y_true, y_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Classification Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Overall Accuracy (OA):     {oa:.4f}\")\n",
        "print(f\"Average Accuracy (AA):      {aa:.4f}\")\n",
        "print(f\"Kappa Coefficient:          {kappa:.4f}\")\n",
        "print(f\"F1 Score (weighted):         {f1:.4f}\")\n",
        "print(f\"Precision (weighted):        {precision:.4f}\")\n",
        "print(f\"Recall (weighted):           {recall:.4f}\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Performance Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create test data loader for performance metrics\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Calculate performance metrics\n",
        "latency = calculate_latency_per_image(model, test_loader, device)\n",
        "throughput = calculate_throughput(model, test_loader, device)\n",
        "params = count_model_parameters(model)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Performance Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Latency per image:          {latency:.4f} ms\")\n",
        "print(f\"Throughput:                  {throughput:.2f} samples/sec\")\n",
        "print(f\"Model Parameters:            {params:.2f} M\")\n",
        "if gflops is not None:\n",
        "    print(f\"GFLOPs:                      {gflops:.2f}\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(14, 12))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Count'})\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title('Confusion Matrix - Houston Dataset', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Per-Class Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate per-class accuracy\n",
        "class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
        "class_names = [f\"Class {i+1}\" for i in range(num_classes)]\n",
        "\n",
        "# Plot per-class accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "bars = plt.bar(range(num_classes), class_accuracies, color='steelblue', alpha=0.7)\n",
        "plt.xlabel('Class', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.title('Per-Class Accuracy - Houston Dataset', fontsize=14, fontweight='bold')\n",
        "plt.xticks(range(num_classes), class_names, rotation=45, ha='right')\n",
        "plt.ylim([0, 1])\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, acc) in enumerate(zip(bars, class_accuracies)):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{acc:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPer-Class Accuracies:\")\n",
        "for i, acc in enumerate(class_accuracies):\n",
        "    print(f\"  {class_names[i]}: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Training completed successfully! The model has been trained on the Houston hyperspectral dataset.\n",
        "\n",
        "### Key Results:\n",
        "- Overall Accuracy, Average Accuracy, and Kappa Coefficient are displayed above\n",
        "- Confusion matrix shows per-class performance\n",
        "- Performance metrics include latency, throughput, and model size\n",
        "\n",
        "### Model Checkpoints:\n",
        "The trained model is saved in `./results_houston/` directory. You can load it later using:\n",
        "```python\n",
        "from transformers import Trainer\n",
        "trainer = Trainer.from_pretrained('./results_houston/checkpoint-<best>')\n",
        "```\n",
        "\n",
        "### Next Steps:\n",
        "- Download the model checkpoints from Colab\n",
        "- Use the trained model for inference on new data\n",
        "- Experiment with different hyperparameters\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}