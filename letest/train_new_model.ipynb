{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training New Model Architecture on Pavia University Dataset\n",
        "\n",
        "This notebook trains the new model architecture from `model.py` on the Pavia University hyperspectral dataset.\n",
        "\n",
        "## Model Architecture\n",
        "- **newFastViT**: A novel Fast Vision Transformer with:\n",
        "  - Efficient Attention mechanism\n",
        "  - Spectral Attention module\n",
        "  - Transformer blocks with residual connections\n",
        "  - Optimized for hyperspectral image classification\n",
        "\n",
        "## Dataset\n",
        "- **Pavia University**: 610×340 pixels, 103 spectral bands\n",
        "- **Classes**: 9 land-cover categories\n",
        "- **Window Size**: 5×5 spatial patches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import scipy.io\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score, precision_score, recall_score, f1_score\n",
        "import time\n",
        "from einops import rearrange\n",
        "from thop import profile\n",
        "\n",
        "# Import custom modules\n",
        "from data_loader import load_pavia_university, preprocess_data, PaviaUniversityDataset\n",
        "from model import newFastViT\n",
        "from utils import (\n",
        "    calculate_latency_per_image,\n",
        "    calculate_throughput,\n",
        "    overall_accuracy,\n",
        "    average_accuracy,\n",
        "    kappa_coefficient,\n",
        "    calculate_f1_precision_recall,\n",
        "    count_model_parameters,\n",
        "    calculate_gflops\n",
        ")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Dataset\n",
        "\n",
        "Load the Pavia University hyperspectral dataset. Update the file paths according to your dataset location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update these paths to point to your dataset files\n",
        "image_file = \"/content/PaviaU.mat\"  # Update this path\n",
        "gt_file = \"/content/PaviaU_gt.mat\"  # Update this path\n",
        "\n",
        "# Load the dataset\n",
        "image_data, ground_truth = load_pavia_university(image_file, gt_file)\n",
        "print(f\"\\nDataset loaded successfully!\")\n",
        "print(f\"Image data shape: {image_data.shape}\")\n",
        "print(f\"Ground truth shape: {ground_truth.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Preprocess Data\n",
        "\n",
        "Preprocess the data to extract spatial-spectral patches and prepare labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess data with 5x5 window size\n",
        "window_size = 5\n",
        "spatial_spectral_data, y, label_encoder = preprocess_data(image_data, ground_truth, window_size=window_size)\n",
        "\n",
        "print(f\"\\nData preprocessed successfully!\")\n",
        "print(f\"Spatial-spectral data shape: {spatial_spectral_data.shape}\")\n",
        "print(f\"Labels shape: {y.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(y))}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Split Dataset\n",
        "\n",
        "Split the dataset into training and testing sets with stratification to maintain class distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split dataset: 80% train, 20% test\n",
        "train_indices, test_indices = train_test_split(\n",
        "    np.arange(len(y)), \n",
        "    test_size=0.2, \n",
        "    stratify=y, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = PaviaUniversityDataset(spatial_spectral_data[train_indices], y[train_indices])\n",
        "test_dataset = PaviaUniversityDataset(spatial_spectral_data[test_indices], y[test_indices])\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Testing samples: {len(test_dataset)}\")\n",
        "print(f\"Train class distribution: {np.bincount(y[train_indices])}\")\n",
        "print(f\"Test class distribution: {np.bincount(y[test_indices])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Initialize Model\n",
        "\n",
        "Initialize the new model architecture from `model.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the new model\n",
        "num_classes = len(np.unique(y))\n",
        "num_channels = spatial_spectral_data.shape[-1]  # 103 spectral bands\n",
        "\n",
        "# IMPORTANT: embed_dim must be divisible by num_heads\n",
        "# For patch_size=4 with image_size=5, the number of patches will be:\n",
        "# floor((image_size - patch_size) / patch_size) + 1 = floor((5-4)/4) + 1 = 1\n",
        "# So we get 1 patch total\n",
        "\n",
        "# Model configuration\n",
        "patch_size = 4\n",
        "embed_dim = 192  # Must be divisible by num_heads (192 / 4 = 48)\n",
        "num_heads = 4\n",
        "depth = 4\n",
        "\n",
        "# Validate configuration\n",
        "if embed_dim % num_heads != 0:\n",
        "    raise ValueError(f\"embed_dim ({embed_dim}) must be divisible by num_heads ({num_heads})\")\n",
        "\n",
        "# Calculate actual number of patches that will be created\n",
        "# Conv2d with kernel_size=patch_size, stride=patch_size on image_size x image_size\n",
        "# Output size = floor((image_size - patch_size) / patch_size) + 1\n",
        "actual_patches_h = (window_size - patch_size) // patch_size + 1\n",
        "actual_patches_w = (window_size - patch_size) // patch_size + 1\n",
        "actual_num_patches = actual_patches_h * actual_patches_w\n",
        "\n",
        "print(f\"Model Configuration:\")\n",
        "print(f\"  Image size: {window_size}x{window_size}\")\n",
        "print(f\"  Patch size: {patch_size}x{patch_size}\")\n",
        "print(f\"  Actual patches: {actual_patches_h}x{actual_patches_w} = {actual_num_patches}\")\n",
        "print(f\"  Embed dim: {embed_dim} (divisible by num_heads={num_heads} ✓)\")\n",
        "print(f\"  Head dim: {embed_dim // num_heads}\")\n",
        "print(f\"  Depth: {depth}\")\n",
        "\n",
        "model = newFastViT(\n",
        "    image_size=window_size,\n",
        "    patch_size=patch_size,\n",
        "    num_channels=num_channels,\n",
        "    num_classes=num_classes,\n",
        "    embed_dim=embed_dim,\n",
        "    depth=depth,\n",
        "    num_heads=num_heads,\n",
        "    mlp_ratio=4.0\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(f\"\\nModel initialized successfully!\")\n",
        "print(f\"Model device: {device}\")\n",
        "print(f\"Number of parameters: {count_model_parameters(model):.2f} M\")\n",
        "\n",
        "# Calculate GFLOPs\n",
        "try:\n",
        "    gflops = calculate_gflops(model, train_dataset, device)\n",
        "    print(f\"GFLOPs: {gflops:.2f}\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not calculate GFLOPs: {e}\")\n",
        "    print(\"This is okay, you can proceed with training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Setup Training\n",
        "\n",
        "Configure training arguments and create the trainer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_new_model\",\n",
        "    num_train_epochs=20,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=3,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False\n",
        ")\n",
        "\n",
        "# Data collator\n",
        "def data_collator(data):\n",
        "    return {\n",
        "        'x': torch.stack([d['x'] for d in data]),\n",
        "        'labels': torch.stack([d['labels'] for d in data])\n",
        "    }\n",
        "\n",
        "# Compute metrics function\n",
        "def compute_metrics(p):\n",
        "    predictions = p.predictions.argmax(-1)\n",
        "    labels = p.label_ids\n",
        "    accuracy = (predictions == labels).mean()\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "print(\"Trainer setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Train Model\n",
        "\n",
        "Train the model on the training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Evaluate Model\n",
        "\n",
        "Evaluate the trained model on the test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"\\nEvaluation Results:\")\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"{key}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Generate Predictions and Calculate Metrics\n",
        "\n",
        "Generate predictions and calculate comprehensive classification metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "y_true = y[test_indices]\n",
        "\n",
        "# Calculate metrics\n",
        "oa = overall_accuracy(y_true, y_pred)\n",
        "aa = average_accuracy(y_true, y_pred)\n",
        "kappa = kappa_coefficient(y_true, y_pred)\n",
        "f1, precision, recall = calculate_f1_precision_recall(y_true, y_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Classification Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Overall Accuracy (OA):     {oa:.4f}\")\n",
        "print(f\"Average Accuracy (AA):      {aa:.4f}\")\n",
        "print(f\"Kappa Coefficient:          {kappa:.4f}\")\n",
        "print(f\"F1 Score (weighted):         {f1:.4f}\")\n",
        "print(f\"Precision (weighted):        {precision:.4f}\")\n",
        "print(f\"Recall (weighted):           {recall:.4f}\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Performance Metrics\n",
        "\n",
        "Calculate model performance metrics including latency, throughput, and parameter count.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create test data loader for performance metrics\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Calculate performance metrics\n",
        "latency = calculate_latency_per_image(model, test_loader, device)\n",
        "throughput = calculate_throughput(model, test_loader, device)\n",
        "params = count_model_parameters(model)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Performance Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Latency per image:          {latency:.4f} ms\")\n",
        "print(f\"Throughput:                  {throughput:.2f} samples/sec\")\n",
        "print(f\"Model Parameters:            {params:.2f} M\")\n",
        "print(f\"GFLOPs:                      {gflops:.2f}\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Confusion Matrix\n",
        "\n",
        "Visualize the confusion matrix to understand classification performance per class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Count'})\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title('Confusion Matrix - New Model Architecture', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Per-Class Accuracy\n",
        "\n",
        "Visualize per-class accuracy to identify which classes are performing well.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate per-class accuracy\n",
        "class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
        "class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
        "\n",
        "# Plot per-class accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(range(num_classes), class_accuracies, color='steelblue', alpha=0.7)\n",
        "plt.xlabel('Class', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.title('Per-Class Accuracy - New Model Architecture', fontsize=14, fontweight='bold')\n",
        "plt.xticks(range(num_classes), class_names, rotation=45, ha='right')\n",
        "plt.ylim([0, 1])\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, acc) in enumerate(zip(bars, class_accuracies)):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{acc:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPer-Class Accuracies:\")\n",
        "for i, acc in enumerate(class_accuracies):\n",
        "    print(f\"  {class_names[i]}: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook successfully trained the new model architecture (`newFastViT`) from `model.py` on the Pavia University hyperspectral dataset. The model uses:\n",
        "\n",
        "- **Efficient Attention**: Optimized attention mechanism for faster computation\n",
        "- **Spectral Attention**: Specialized attention for spectral band processing\n",
        "- **Transformer Blocks**: 6 layers with residual connections\n",
        "- **Spatial-Spectral Processing**: 5×5 patches with 103 spectral bands\n",
        "\n",
        "### Key Results:\n",
        "- Overall Accuracy, Average Accuracy, and Kappa Coefficient are displayed above\n",
        "- Confusion matrix shows per-class performance\n",
        "- Performance metrics include latency, throughput, and model size\n",
        "\n",
        "The trained model is saved in `./results_new_model/` directory.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
